# ==============================================================================
# SoundFlow - GCP Environment Configuration
# Copy this file to .env.gcp and fill in your values
# ==============================================================================

# GCP Project Configuration
GCP_PROJECT=your-gcp-project-id
GCP_REGION=asia-southeast1

# Terraform Variables (optional, can also set in terraform.tfvars)
TF_VAR_project_id=${GCP_PROJECT}
TF_VAR_region=${GCP_REGION}
TF_VAR_environment=dev

# BigQuery Configuration
BQ_LOCATION=asia-southeast1

# GCS Configuration
GCS_BUCKET=soundflow-${GCP_PROJECT}-data

# Service Account Credentials
# After running terraform, credentials will be in terraform/credentials/
GOOGLE_APPLICATION_CREDENTIALS=./terraform/credentials/pipeline-sa-key.json

# Spark Streaming Configuration
SOURCE_TYPE=pubsub  # "kafka" for local, "pubsub" for GCP
TRIGGER_INTERVAL=2 minutes
CHECKPOINT_LOCATION=gs://${GCS_BUCKET}/checkpoints/spark

# dbt Configuration
DBT_TARGET=prod

# Pub/Sub Configuration (auto-generated by Terraform)
# PUBSUB_PROJECT=${GCP_PROJECT}
# PUBSUB_SUBSCRIPTION_PREFIX=spark

# Docker/Container Registry
GCR_HOST=gcr.io/${GCP_PROJECT}
