# =====================================================
# SOUNDFLOW - DATA STREAMING PIPELINE
# Environment Variables Template
# Copy this file to .env.local for local development
# =====================================================

# ====================
# Local PostgreSQL (for local development)
# ====================
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=soundflow
POSTGRES_USER=soundflow
POSTGRES_PASSWORD=your_secure_password_here

# ====================
# GCP Configuration (for cloud deployment)
# ====================
GCP_PROJECT=your-gcp-project-id
GCS_BUCKET=soundflow-data-lake
GCP_REGION=asia-southeast1
GOOGLE_APPLICATION_CREDENTIALS=/opt/spark/credentials/gcp-key.json

# ====================
# BigQuery Configuration
# ====================
BQ_DATASET=soundflow
BQ_LOCATION=asia-southeast1

# ====================
# Kafka/Redpanda Configuration
# ====================
KAFKA_BOOTSTRAP_SERVERS=redpanda:29092

# ====================
# Spark Configuration
# ====================
SPARK_MASTER=local[*]
TRIGGER_INTERVAL=30 seconds
CHECKPOINT_LOCATION=/app/checkpoints

# ====================
# Dagster Configuration
# ====================
DAGSTER_HOME=/opt/dagster/dagster_home
DAGSTER_PORT=3000

# ====================
# dbt Configuration
# ====================
DBT_TARGET=local
DBT_PROFILES_DIR=/app/dbt

# ====================
# EventSim Configuration
# ====================
EVENTSIM_NUSERS=100
EVENTSIM_FROM_DAYS=7
EVENTSIM_TO_DAYS=1
