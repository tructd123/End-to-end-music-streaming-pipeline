# SoundFlow - Music Streaming Data Pipeline

End-to-end real-time data pipeline for music streaming analytics, similar to Spotify.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Eventsim   â”‚â”€â”€â”€â–¶â”‚   Redpanda   â”‚â”€â”€â”€â–¶â”‚  Spark Streamingâ”‚â”€â”€â”€â–¶â”‚    GCS      â”‚
â”‚ (Generator) â”‚    â”‚   (Broker)   â”‚    â”‚  (Every 2 min)  â”‚    â”‚ (Data Lake) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                                     â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    Dagster      â”‚â”€â”€â”€â–¶â”‚    BigQuery     â”‚â”€â”€â”€â–¶â”‚    Power BI     â”‚
          â”‚ (Hourly Batch)  â”‚    â”‚  + dbt Models   â”‚    â”‚   (Dashboard)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Components

| Component | Description | Port |
|-----------|-------------|------|
| **Eventsim** | Simulates music streaming events | - |
| **Redpanda** | Kafka-compatible message broker | 9092 |
| **Redpanda Console** | Web UI for Redpanda | 8080 |
| **Spark Streaming** | Stream processing (2-min micro-batches) | - |
| **Dagster** | Workflow orchestration (hourly jobs) | 3000 |
| **dbt** | Data transformation in BigQuery | - |
| **BigQuery** | Data warehouse | - |
| **Power BI** | Visualization | - |

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- GCP Account with billing enabled
- Terraform >= 1.0

### Step 1: Setup GCP Infrastructure

```bash
cd terraform

# Copy and edit variables
cp terraform.tfvars.example terraform.tfvars
# Edit terraform.tfvars with your GCP project ID

# Initialize and apply
terraform init
terraform plan
terraform apply
```

### Step 2: Configure Environment

```bash
cd ..

# Copy environment file
cp .env.example .env

# Edit .env with your GCP settings
# - GCP_PROJECT
# - GCS_BUCKET
```

### Step 3: Start the Pipeline

```bash
# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f eventsim
docker-compose logs -f spark-streaming
```

### Step 4: Access UIs

- **Redpanda Console**: http://localhost:8080
- **Dagster**: http://localhost:3000

## ğŸ“Š Business Questions Answered

The pipeline provides data marts to answer:

1. **ğŸµ What songs are most popular?**
   - `mart_top_songs`: Ranked by plays, listeners, popularity score

2. **ğŸ‘¥ Who are the active users?**
   - `mart_active_users`: User segments by activity and engagement

3. **ğŸ“ Where are they from?**
   - `mart_location_analytics`: Geographic distribution and metrics

## ğŸ“ Project Structure

```
Data_streaming_pipeline/
â”œâ”€â”€ docker-compose.yml          # Master orchestration
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ credentials/                # GCP service account key
â”‚   â””â”€â”€ gcp-key.json           # (generated by Terraform)
â”œâ”€â”€ eventsim/                   # Event generator
â”œâ”€â”€ redpanda/                   # Message broker config
â”œâ”€â”€ spark_streaming/            # Stream processing
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ streaming_to_gcs.py
â”‚       â””â”€â”€ config.py
â”œâ”€â”€ dagster/                    # Orchestration
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ dagster_pipeline/
â”œâ”€â”€ dbt/                        # Transformations
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ staging/
â”‚       â”œâ”€â”€ intermediate/
â”‚       â””â”€â”€ marts/
â””â”€â”€ terraform/                  # Infrastructure as Code
    â”œâ”€â”€ main.tf
    â”œâ”€â”€ variables.tf
    â””â”€â”€ outputs.tf
```

## ğŸ”„ Data Flow

1. **Eventsim** generates fake music streaming events
2. **Redpanda** receives events in 4 topics:
   - `listen_events`
   - `page_view_events`
   - `auth_events`
   - `status_change_events`
3. **Spark Streaming** consumes and writes to GCS every 2 minutes
4. **Dagster** runs hourly to:
   - Load GCS â†’ BigQuery staging tables
   - Trigger dbt transformations
5. **dbt** transforms data:
   - `staging/` â†’ Clean raw data
   - `intermediate/` â†’ Aggregate metrics
   - `marts/` â†’ Business-ready tables
6. **Power BI** connects to BigQuery marts

## ğŸ› ï¸ Development

### Run dbt locally

```bash
cd dbt
pip install dbt-bigquery

# Set environment variables
export GCP_PROJECT=your-project-id
export GOOGLE_APPLICATION_CREDENTIALS=../credentials/gcp-key.json

# Run dbt
dbt deps
dbt debug
dbt run
dbt test
```

### Run Dagster locally

```bash
cd dagster
pip install -r requirements.txt

export DAGSTER_HOME=$(pwd)/dagster_home
dagster dev
```

## ğŸ“ˆ Scaling Considerations

For production:

1. **Redpanda**: Use managed Redpanda Cloud or multi-node cluster
2. **Spark**: Use Dataproc or Kubernetes
3. **Dagster**: Use Dagster Cloud
4. **dbt**: Use dbt Cloud for scheduling

## ğŸ“ License

MIT
